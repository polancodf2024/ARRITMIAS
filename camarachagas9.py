import streamlit as st
import cv2
import numpy as np
from PIL import Image, ImageEnhance, ImageFilter
import tempfile
import os
import time
from datetime import datetime
import logging
from scipy import ndimage
from skimage import filters, measure, morphology
import pytesseract
from difflib import SequenceMatcher
import re
import json
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import joblib
import shutil
import paramiko
from io import StringIO, BytesIO
import base64
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from datetime import timedelta
import matplotlib.ticker as ticker

# Configuraci√≥n de logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Configuraci√≥n de matplotlib para mejor visualizaci√≥n
plt.style.use('seaborn-v0_8-whitegrid')
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['font.size'] = 10
plt.rcParams['figure.figsize'] = (10, 6)

# Configuraci√≥n de pytesseract (OCR)
try:
    pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'
except:
    try:
        pytesseract.pytesseract.tesseract_cmd = '/usr/bin/tesseract'
    except:
        st.warning("Tesseract OCR no encontrado. La detecci√≥n de texto estar√° limitada.")

# Configuraci√≥n remota desde secrets.toml
REMOTE_HOST = st.secrets.get("remote_host", "187.217.52.137")
REMOTE_USER = st.secrets.get("remote_user", "POLANCO6")
REMOTE_PASSWORD = st.secrets.get("remote_password", "tt6plco6")
REMOTE_PORT = st.secrets.get("remote_port", 3792)
REMOTE_DIR = st.secrets.get("remote_dir", "/home/POLANCO6/CHAGAS")
REMOTE_CHAGAS = st.secrets.get("remote_chagas", "registro_chagas.csv")

# Nombres de archivos remotos
REMOTE_DATASET = "registro_chagas.csv"
REMOTE_MODEL = "chagas_model.pkl"
REMOTE_IMAGES_DIR = "training_images"
REMOTE_HISTORY = "accuracy_history.json"

# Categor√≠as de resultado v√°lidas
RESULT_CATEGORIES = ["POSITIVE", "NEGATIVE", "WEAK POSITIVE", "INVALID"]

# N√∫mero fijo de caracter√≠sticas para garantizar consistencia
NUM_FEATURES = 20

def check_camera_access():
    """Verifica y gu√≠a sobre el acceso a la c√°mara - MEJORADO"""
    st.markdown("""
    <div style='background-color: #fff3cd; padding: 15px; border-radius: 10px; border-left: 5px solid #ffc107; margin: 10px 0;'>
    <h4>üîß SOLUCI√ìN PARA PROBLEMAS DE C√ÅMARA</h4>
    
    <strong>üì± PARA M√ìVILES:</strong>
    ‚Ä¢ Aseg√∫rate de usar HTTPS (Streamlit Cloud lo proporciona autom√°ticamente)
    ‚Ä¢ Permite el acceso a la c√°mara cuando el navegador lo solicite
    ‚Ä¢ Usa Chrome o Safari para mejor compatibilidad
    
    <strong>üíª PARA LAPTOP:</strong>
    ‚Ä¢ <strong>Ejecuta localmente:</strong> <code>streamlit run camarachagas8.py</code>
    ‚Ä¢ <strong>Abre en Chrome:</strong> http://localhost:8501
    ‚Ä¢ <strong>Permite c√°mara:</strong> Cuando el navegador lo solicite
    
    <strong>üîÑ ALTERNATIVA SI NO FUNCIONA:</strong>
    ‚Ä¢ Usa la opci√≥n <strong>SUBIR ARCHIVO</strong> üìÅ - funciona igual de bien
    ‚Ä¢ Verifica que la c√°mara funcione en otras aplicaciones
    ‚Ä¢ Reinicia el navegador y prueba de nuevo
    </div>
    """, unsafe_allow_html=True)

def check_https_status():
    """Verifica si est√° usando HTTPS (requerido para c√°mara en producci√≥n) - MEJORADO"""
    try:
        st.markdown("""
        <div style='background-color: #d4edda; padding: 15px; border-radius: 10px; border-left: 5px solid #28a745; margin: 10px 0;'>
        <h4>‚úÖ CONEXI√ìN SEGURA HTTPS ACTIVADA</h4>
        <p>Esta app est√° usando conexi√≥n segura HTTPS. La c√°mara deber√≠a funcionar en dispositivos m√≥viles.</p>
        <p><strong>üí° CONSEJO:</strong> Para mejor funcionamiento en laptop, ejecuta localmente: <code>streamlit run camarachagas8.py</code></p>
        </div>
        """, unsafe_allow_html=True)
    except:
        pass

def enhance_camera_capture():
    """Configuraci√≥n MEJORADA para la c√°mara - Funciona en laptop y m√≥vil"""
    st.markdown("""
    <style>
    .camera-container {
        border: 2px solid #4CAF50;
        border-radius: 10px;
        padding: 10px;
        background: #f9f9f9;
        margin: 10px 0;
    }
    .camera-warning {
        background-color: #fff3cd;
        border: 1px solid #ffeaa7;
        border-radius: 5px;
        padding: 10px;
        margin: 10px 0;
    }
    </style>
    """, unsafe_allow_html=True)
    
    st.markdown("""
    <div class='camera-warning'>
    <strong>üì∏ CONSEJOS PARA MEJOR CAPTURA:</strong><br>
    ‚Ä¢ <strong>Enfoca bien</strong> la tira reactiva<br>
    ‚Ä¢ <strong>Buena iluminaci√≥n</strong> para imagen clara<br>
    ‚Ä¢ Aseg√∫rate que las letras <strong>C</strong> y <strong>T</strong> sean visibles<br>
    ‚Ä¢ Mant√©n la c√°mara <strong>estable</strong> al tomar la foto
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown('<div class="camera-container">', unsafe_allow_html=True)
    
    try:
        picture = st.camera_input(
            "üì∏ Toma una foto CLARA de la tira reactiva de Chagas",
            help="Aseg√∫rate de permitir el acceso a la c√°mara. Si no funciona, usa la opci√≥n de Subir Archivo."
        )
        
        st.markdown('</div>', unsafe_allow_html=True)
        return picture
        
    except Exception as e:
        st.markdown('</div>', unsafe_allow_html=True)
        st.error(f"‚ùå Error con la c√°mara: {e}")
        st.info("üí° Usa la opci√≥n de **Subir Archivo** como alternativa")
        return None

def initialize_learning_system():
    """Inicializa el sistema de aprendizaje desde servidor remoto"""
    if 'learning_data' not in st.session_state:
        st.session_state.learning_data = load_remote_learning_data()
    
    if 'model' not in st.session_state:
        st.session_state.model = load_or_create_remote_model()
    
    if 'accuracy_history' not in st.session_state:
        st.session_state.accuracy_history = load_remote_accuracy_history()
    
    if 'training_count' not in st.session_state:
        st.session_state.training_count = len(st.session_state.accuracy_history)
    
    if 'show_correction' not in st.session_state:
        st.session_state.show_correction = False
    
    if 'auto_corrections' not in st.session_state:
        st.session_state.auto_corrections = 0
    
    if 'camera_working' not in st.session_state:
        st.session_state.camera_working = True

def connect_remote():
    """Conecta al servidor remoto"""
    try:
        ssh = paramiko.SSHClient()
        ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
        ssh.connect(REMOTE_HOST, port=REMOTE_PORT, username=REMOTE_USER, password=REMOTE_PASSWORD)
        return ssh
    except Exception as e:
        logger.error(f"Error conectando al servidor remoto: {e}")
        return None

def execute_remote_command(command):
    """Ejecuta comando en servidor remoto"""
    try:
        ssh = connect_remote()
        if ssh is None:
            return False
        
        stdin, stdout, stderr = ssh.exec_command(command)
        exit_status = stdout.channel.recv_exit_status()
        ssh.close()
        return exit_status == 0
    except Exception as e:
        logger.error(f"Error ejecutando comando remoto: {e}")
        return False

def ensure_remote_directories():
    """Asegura que los directorios remotos existan"""
    try:
        commands = [
            f"mkdir -p {REMOTE_DIR}",
            f"mkdir -p {REMOTE_DIR}/{REMOTE_IMAGES_DIR}"
        ]
        
        for cmd in commands:
            if not execute_remote_command(cmd):
                logger.warning(f"No se pudo crear directorio con comando: {cmd}")
                return False
        return True
    except Exception as e:
        logger.error(f"Error creando directorios remotos: {e}")
        return False

def create_remote_headers():
    """Crea el archivo remoto con encabezados si no existe"""
    try:
        ssh = connect_remote()
        if ssh is None:
            st.error("No se pudo conectar al servidor remoto")
            return False
        
        sftp = ssh.open_sftp()
        remote_path = f"{REMOTE_DIR}/{REMOTE_DATASET}"
        
        # Verificar si el archivo existe y tiene contenido
        try:
            with sftp.open(remote_path, 'r') as f:
                content = f.read(100)  # Leer primeros 100 bytes
                if len(content) > 0:
                    st.info("El archivo remoto ya existe y tiene contenido")
                    sftp.close()
                    ssh.close()
                    return True
        except:
            pass  # El archivo no existe o est√° vac√≠o
        
        # Crear archivo con encabezados
        headers = "timestamp,features,predicted_result,correct_result,confidence,quality_score,evaluation_type,source,analysis_id\n"
        
        with sftp.open(remote_path, 'w') as f:
            f.write(headers)
        
        sftp.close()
        ssh.close()
        st.success("‚úÖ Encabezados creados en archivo remoto")
        return True
        
    except Exception as e:
        st.error(f"Error creando encabezados: {e}")
        return False

def load_remote_learning_data():
    """Carga los datos de aprendizaje del archivo remoto - VERSI√ìN CORREGIDA"""
    try:
        ssh = connect_remote()
        if ssh is None:
            st.warning("No se pudo conectar al servidor remoto. Usando datos vac√≠os.")
            return []
        
        ensure_remote_directories()
        
        sftp = ssh.open_sftp()
        remote_path = f"{REMOTE_DIR}/{REMOTE_DATASET}"
        
        try:
            # Verificar si el archivo existe y tiene contenido
            file_stats = sftp.stat(remote_path)
            if file_stats.st_size == 0:
                st.info("üÜï Archivo remoto existe pero est√° vac√≠o")
                sftp.close()
                ssh.close()
                return []
            
            with sftp.open(remote_path, 'r') as remote_file:
                # Leer primeras l√≠neas para verificar encabezados
                first_lines = []
                for i in range(2):  # Leer primeras 2 l√≠neas
                    line = remote_file.readline()
                    if line:
                        first_lines.append(line.strip())
                
                # Si no hay suficientes l√≠neas o no tiene encabezados v√°lidos
                if len(first_lines) < 1 or 'timestamp' not in first_lines[0]:
                    st.warning("‚ùå Archivo remoto no tiene formato v√°lido. Se crear√° uno nuevo.")
                    sftp.close()
                    ssh.close()
                    create_remote_headers()  # Crear encabezados
                    return []
                
                # Volver al inicio y cargar datos normalmente
                remote_file.seek(0)
                df = pd.read_csv(remote_file)
                
                if len(df) == 0:
                    st.info("üì≠ Archivo remoto tiene encabezados pero no datos")
                    sftp.close()
                    ssh.close()
                    return []
                
                if 'features' in df.columns:
                    df['features'] = df['features'].apply(lambda x: eval(x) if isinstance(x, str) else x)
                
                st.success(f"‚úÖ Datos remotos cargados: {len(df)} ejemplos")
                sftp.close()
                ssh.close()
                return df.to_dict('records')
                
        except FileNotFoundError:
            st.info("üÜï No hay archivo de datos remotos")
            sftp.close()
            ssh.close()
            return []
        except pd.errors.EmptyDataError:
            st.warning("üì≠ Archivo remoto est√° vac√≠o")
            sftp.close()
            ssh.close()
            return []
        except Exception as e:
            st.warning(f"‚ö†Ô∏è Error leyendo archivo remoto: {e}")
            sftp.close()
            ssh.close()
            return []
            
    except Exception as e:
        st.error(f"Error cargando datos remotos: {e}")
        return []

def save_remote_learning_data():
    """Guarda los datos de aprendizaje en el archivo remoto"""
    try:
        if not st.session_state.learning_data:
            st.info("No hay datos para guardar")
            return
            
        ssh = connect_remote()
        if ssh is None:
            st.error("‚ùå No se pudo conectar al servidor remoto para guardar datos")
            return
        
        ensure_remote_directories()
        
        # Asegurar que todas las features tengan la misma longitud
        for item in st.session_state.learning_data:
            if 'features' in item and len(item['features']) != NUM_FEATURES:
                item['features'] = ensure_feature_length(item['features'])
        
        df = pd.DataFrame(st.session_state.learning_data)
        
        sftp = ssh.open_sftp()
        remote_path = f"{REMOTE_DIR}/{REMOTE_DATASET}"
        
        # Guardar en archivo temporal primero
        temp_csv = "temp_chagas_data.csv"
        df.to_csv(temp_csv, index=False)
        
        # Subir al servidor remoto
        sftp.put(temp_csv, remote_path)
        
        # Limpiar archivo temporal
        os.remove(temp_csv)
        
        sftp.close()
        ssh.close()
        
        st.success(f"üíæ Datos guardados remotamente: {len(df)} ejemplos en {REMOTE_DATASET}")
        
    except Exception as e:
        logger.error(f"Error guardando datos remotos: {e}")
        st.error("‚ùå Error guardando datos en servidor remoto")

def load_or_create_remote_model():
    """Carga un modelo existente o crea uno nuevo desde servidor remoto"""
    try:
        ssh = connect_remote()
        if ssh is None:
            st.warning("No se pudo conectar al servidor remoto. Creando modelo local temporal.")
            return RandomForestClassifier(n_estimators=50, random_state=42, max_depth=10)
        
        sftp = ssh.open_sftp()
        remote_path = f"{REMOTE_DIR}/{REMOTE_MODEL}"
        
        try:
            # Verificar si el archivo existe y tiene tama√±o
            file_stats = sftp.stat(remote_path)
            if file_stats.st_size == 0:
                st.info("üÜï Modelo remoto existe pero est√° vac√≠o. Creando nuevo.")
                model = RandomForestClassifier(n_estimators=50, random_state=42, max_depth=10)
                sftp.close()
                ssh.close()
                return model
            
            # Descargar modelo remoto
            temp_model = "temp_model.pkl"
            sftp.get(remote_path, temp_model)
            
            model = joblib.load(temp_model)
            os.remove(temp_model)
            
            st.success("‚úÖ Modelo de aprendizaje cargado desde servidor remoto")
            sftp.close()
            ssh.close()
            return model
            
        except FileNotFoundError:
            st.info("üÜï No hay modelo remoto previo. Creando nuevo modelo.")
            model = RandomForestClassifier(n_estimators=50, random_state=42, max_depth=10)
            sftp.close()
            ssh.close()
            return model
            
    except Exception as e:
        st.warning(f"Creando nuevo modelo: {e}")
        return RandomForestClassifier(n_estimators=50, random_state=42, max_depth=10)

def save_remote_model():
    """Guarda el modelo entrenado en el servidor remoto"""
    try:
        ssh = connect_remote()
        if ssh is None:
            st.error("‚ùå No se pudo conectar al servidor remoto para guardar modelo")
            return
        
        ensure_remote_directories()
        
        sftp = ssh.open_sftp()
        remote_path = f"{REMOTE_DIR}/{REMOTE_MODEL}"
        
        # Guardar en archivo temporal primero
        temp_model = "temp_model.pkl"
        joblib.dump(st.session_state.model, temp_model)
        
        # Subir al servidor remoto
        sftp.put(temp_model, remote_path)
        
        # Limpiar archivo temporal
        os.remove(temp_model)
        
        sftp.close()
        ssh.close()
        
        st.success(f"üíæ Modelo guardado en servidor remoto: {REMOTE_MODEL}")
        
    except Exception as e:
        logger.error(f"Error guardando modelo remoto: {e}")
        st.error("‚ùå Error guardando modelo en servidor remoto")

def load_remote_accuracy_history():
    """Carga el historial de precisi√≥n desde servidor remoto"""
    try:
        ssh = connect_remote()
        if ssh is None:
            return []
        
        sftp = ssh.open_sftp()
        remote_path = f"{REMOTE_DIR}/{REMOTE_HISTORY}"
        
        try:
            # Verificar si el archivo existe y tiene contenido
            file_stats = sftp.stat(remote_path)
            if file_stats.st_size == 0:
                sftp.close()
                ssh.close()
                return []
            
            with sftp.open(remote_path, 'r') as remote_file:
                history = json.load(remote_file)
                sftp.close()
                ssh.close()
                return history
        except FileNotFoundError:
            sftp.close()
            ssh.close()
            return []
        except json.JSONDecodeError:
            st.warning("Historial remoto tiene formato inv√°lido")
            sftp.close()
            ssh.close()
            return []
            
    except Exception as e:
        logger.error(f"Error cargando historial remoto: {e}")
        return []

def save_remote_accuracy_history():
    """Guarda el historial de precisi√≥n en el servidor remoto"""
    try:
        if not st.session_state.accuracy_history:
            return
            
        ssh = connect_remote()
        if ssh is None:
            return
        
        ensure_remote_directories()
        
        sftp = ssh.open_sftp()
        remote_path = f"{REMOTE_DIR}/{REMOTE_HISTORY}"
        
        # Guardar en archivo temporal primero
        temp_history = "temp_history.json"
        with open(temp_history, 'w') as f:
            json.dump(st.session_state.accuracy_history, f)
        
        # Subir al servidor remoto
        sftp.put(temp_history, remote_path)
        
        # Limpiar archivo temporal
        os.remove(temp_history)
        
        sftp.close()
        ssh.close()
        
    except Exception as e:
        logger.error(f"Error guardando historial remoto: {e}")

def save_remote_training_image(image_array, analysis_id, correct_result):
    """Guarda imagen para entrenamiento en servidor remoto"""
    try:
        ssh = connect_remote()
        if ssh is None:
            logger.error("No se pudo conectar para guardar imagen")
            return None
        
        ensure_remote_directories()
        
        # Convertir imagen a bytes
        img_pil = Image.fromarray(image_array)
        img_bytes = BytesIO()
        img_pil.save(img_bytes, format='JPEG', quality=90)
        img_bytes.seek(0)
        
        # Nombre del archivo remoto
        filename = f"{analysis_id}_{correct_result}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.jpg"
        remote_path = f"{REMOTE_DIR}/{REMOTE_IMAGES_DIR}/{filename}"
        
        sftp = ssh.open_sftp()
        
        # Subir imagen al servidor remoto
        with sftp.file(remote_path, 'wb') as remote_file:
            remote_file.write(img_bytes.getvalue())
        
        sftp.close()
        ssh.close()
        
        logger.info(f"‚úÖ Imagen guardada remotamente: {filename}")
        return remote_path
        
    except Exception as e:
        logger.error(f"Error guardando imagen remota: {e}")
        return None

def load_remote_images_list():
    """Carga la lista de im√°genes disponibles en el servidor remoto"""
    try:
        ssh = connect_remote()
        if ssh is None:
            return []
        
        sftp = ssh.open_sftp()
        remote_dir = f"{REMOTE_DIR}/{REMOTE_IMAGES_DIR}"
        
        try:
            files = sftp.listdir(remote_dir)
            image_files = [f for f in files if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
            sftp.close()
            ssh.close()
            return image_files
        except FileNotFoundError:
            sftp.close()
            ssh.close()
            return []
            
    except Exception as e:
        logger.error(f"Error listando im√°genes remotas: {e}")
        return []

def load_remote_image(filename):
    """Carga una imagen espec√≠fica desde el servidor remoto"""
    try:
        ssh = connect_remote()
        if ssh is None:
            return None
        
        sftp = ssh.open_sftp()
        remote_path = f"{REMOTE_DIR}/{REMOTE_IMAGES_DIR}/{filename}"
        
        try:
            # Descargar imagen a memoria
            with sftp.open(remote_path, 'rb') as remote_file:
                img_bytes = remote_file.read()
            
            # Convertir bytes a imagen numpy
            img_pil = Image.open(BytesIO(img_bytes))
            img_array = np.array(img_pil)
            
            sftp.close()
            ssh.close()
            return img_array
            
        except FileNotFoundError:
            sftp.close()
            ssh.close()
            return None
            
    except Exception as e:
        logger.error(f"Error cargando imagen remota {filename}: {e}")
        return None

def ensure_feature_length(features, target_length=NUM_FEATURES):
    """Asegura que las caracter√≠sticas tengan la longitud correcta"""
    if len(features) == target_length:
        return features
    elif len(features) > target_length:
        return features[:target_length]
    else:
        return features + [0.0] * (target_length - len(features))

def extract_features_from_analysis(analysis):
    """Extrae caracter√≠sticas para el modelo de ML"""
    try:
        features = []
        
        # 1. Caracter√≠sticas de bandas (6 caracter√≠sticas)
        features.extend([
            float(analysis.get('control_present', 0)),
            float(analysis.get('test_present', 0)),
            float(analysis.get('control_intensity', 0)),
            float(analysis.get('test_intensity', 0)),
            float(analysis.get('intensity_ratio', 0)),
            float(analysis.get('confidence', 0))
        ])
        
        # 2. Caracter√≠sticas de calidad (4 caracter√≠sticas)
        quality = analysis.get('quality_analysis', {})
        features.extend([
            float(quality.get('brightness', 0)),
            float(quality.get('contrast', 0)),
            float(quality.get('sharpness', 0)),
            float(quality.get('quality_score', 0))
        ])
        
        # 3. Caracter√≠sticas de texto (4 caracter√≠sticas)
        text_data = analysis.get('text_detection', {})
        features.extend([
            float(len(text_data.get('keywords', []))),
            float(1 if text_data.get('has_chagas_text') else 0),
            float(1 if text_data.get('has_control_text') else 0),
            float(1 if text_data.get('has_test_text') else 0)
        ])
        
        # 4. Caracter√≠sticas de letras (4 caracter√≠sticas)
        letters_data = analysis.get('letters_detection', {})
        features.extend([
            float(1 if letters_data and letters_data.get('C_detected') else 0),
            float(1 if letters_data and letters_data.get('T_detected') else 0),
            float(letters_data.get('C_confidence', 0) if letters_data else 0),
            float(letters_data.get('T_confidence', 0) if letters_data else 0)
        ])
        
        # 5. Caracter√≠sticas adicionales para completar (2 caracter√≠sticas)
        features.extend([
            float(analysis.get('quality_score', 0) / 100.0),
            float(min(analysis.get('validated_confidence', 0) / 100.0, 1.0))
        ])
        
        features = ensure_feature_length(features, NUM_FEATURES)
        return features
        
    except Exception as e:
        logger.error(f"Error extrayendo caracter√≠sticas: {e}")
        return [0.0] * NUM_FEATURES

def train_model():
    """Entrena el modelo con los datos acumulados y guarda en remoto"""
    if len(st.session_state.learning_data) < 2:  # Reducido a 2 para m√°s agresividad
        st.warning(f"Se necesitan al menos 2 ejemplos para entrenar. Actual: {len(st.session_state.learning_data)}")
        return None
    
    try:
        features = []
        labels = []
        valid_items = 0
        
        for item in st.session_state.learning_data:
            if 'features' in item and 'correct_result' in item:
                if (isinstance(item['features'], (list, np.ndarray)) and 
                    len(item['features']) == NUM_FEATURES and
                    all(isinstance(x, (int, float, np.number)) for x in item['features'])):
                    
                    feature_array = np.array(item['features'], dtype=np.float64)
                    features.append(feature_array)
                    labels.append(item['correct_result'])
                    valid_items += 1
        
        if valid_items < 2:
            st.warning(f"Solo {valid_items} ejemplos v√°lidos para entrenar")
            return None
        
        X = np.array(features)
        y = np.array(labels)
        
        logger.info(f"Forma de X: {X.shape}, Forma de y: {y.shape}")
        
        # Configuraci√≥n m√°s agresiva para pocos datos
        if len(X) < 10:
            st.session_state.model = RandomForestClassifier(
                n_estimators=30, 
                random_state=42, 
                max_depth=5,
                min_samples_split=2,
                min_samples_leaf=1
            )
        
        # Usar todos los datos para entrenamiento si hay pocos
        if len(X) <= 5:
            X_train, X_test, y_train, y_test = X, X, y, y
            test_size = 0.0
        else:
            test_size = min(0.2, 1.0 / len(X))  # Test size m√°s peque√±o
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=test_size, random_state=42, stratify=y
            )
        
        st.session_state.model.fit(X_train, y_train)
        
        # Evaluar
        if len(X_test) > 0:
            y_pred = st.session_state.model.predict(X_test)
            accuracy = accuracy_score(y_test, y_pred)
        else:
            # Si no hay test data, usar training accuracy
            y_pred_train = st.session_state.model.predict(X_train)
            accuracy = accuracy_score(y_train, y_pred_train)
        
        # Guardar TODO en remoto
        save_remote_model()
        save_remote_learning_data()
        
        st.session_state.accuracy_history.append({
            'timestamp': datetime.now().isoformat(),
            'accuracy': accuracy,
            'training_samples': valid_items
        })
        
        save_remote_accuracy_history()
        
        st.session_state.training_count += 1
        return accuracy
        
    except Exception as e:
        logger.error(f"Error entrenando modelo: {e}")
        st.error(f"Error en entrenamiento: {str(e)}")
        return None

def predict_with_model(features):
    """Predice usando el modelo entrenado"""
    try:
        if (len(st.session_state.learning_data) >= 2 and  # Reducido a 2
            hasattr(st.session_state.model, 'classes_') and
            hasattr(st.session_state.model, 'predict')):
            
            features_array = np.array(features, dtype=np.float64).reshape(1, -1)
            prediction = st.session_state.model.predict(features_array)[0]
            probabilities = st.session_state.model.predict_proba(features_array)[0]
            confidence = max(probabilities)
            return prediction, confidence
        else:
            return None, 0
    except Exception as e:
        logger.error(f"Error en predicci√≥n ML: {e}")
        return None, 0

def calculate_image_similarity(img1, img2):
    """Calcula la similitud entre dos im√°genes usando m√∫ltiples m√©todos"""
    try:
        if img1.shape != img2.shape:
            # Redimensionar img2 para que coincida con img1
            img2 = cv2.resize(img2, (img1.shape[1], img1.shape[0]))
        
        # M√©todo 1: SSIM (Structural Similarity)
        gray1 = cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY) if len(img1.shape) == 3 else img1
        gray2 = cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY) if len(img2.shape) == 3 else img2
        
        from skimage.metrics import structural_similarity as ssim
        ssim_score = ssim(gray1, gray2, data_range=gray2.max() - gray2.min())
        
        # M√©todo 2: Histogram comparison
        hist1 = cv2.calcHist([gray1], [0], None, [64], [0, 256])
        hist2 = cv2.calcHist([gray2], [0], None, [64], [0, 256])
        hist_score = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)
        
        # M√©todo 3: MSE (Mean Squared Error)
        mse = np.mean((gray1 - gray2) ** 2)
        mse_score = 1 / (1 + mse)  # Convertir a score entre 0-1
        
        # Combinar scores
        final_score = (ssim_score * 0.5 + hist_score * 0.3 + mse_score * 0.2)
        
        return final_score
        
    except Exception as e:
        logger.error(f"Error calculando similitud: {e}")
        return 0.0

def find_similar_historical_image(current_image, threshold=0.75):  # Umbral m√°s bajo
    """Busca im√°genes similares en el registro hist√≥rico REMOTO"""
    try:
        similar_images = []
        
        # Cargar lista de im√°genes remotas
        remote_images = load_remote_images_list()
        
        if not remote_images:
            return []
        
        for filename in remote_images:
            try:
                # Cargar imagen desde servidor remoto
                historical_img = load_remote_image(filename)
                if historical_img is not None:
                    similarity = calculate_image_similarity(current_image, historical_img)
                    
                    if similarity >= threshold:
                        # Extraer informaci√≥n del nombre del archivo
                        parts = filename.split('_')
                        correct_result = "POSITIVE"  # Por defecto
                        if len(parts) >= 2:
                            # Buscar el resultado en el nombre del archivo
                            for part in parts:
                                if part in RESULT_CATEGORIES:
                                    correct_result = part
                                    break
                        
                        similar_images.append({
                            'filename': filename,
                            'similarity': similarity,
                            'correct_result': correct_result,
                            'analysis_id': parts[0] if len(parts) > 0 else "unknown"
                        })
            except Exception as e:
                logger.warning(f"Error procesando imagen remota {filename}: {e}")
                continue
        
        # Ordenar por similitud (mayor primero)
        similar_images.sort(key=lambda x: x['similarity'], reverse=True)
        return similar_images[:3]  # Retornar las 3 m√°s similares
        
    except Exception as e:
        logger.error(f"Error buscando im√°genes similares remotas: {e}")
        return []

def auto_correct_with_historical_data(current_analysis, current_image):
    """Corrige autom√°ticamente bas√°ndose en im√°genes hist√≥ricas remotas"""
    try:
        similar_images = find_similar_historical_image(current_image, threshold=0.70)  # Umbral m√°s bajo
        
        if not similar_images:
            return current_analysis['validated_result'], current_analysis['validated_confidence'], "No se encontraron im√°genes similares en el servidor remoto"
        
        best_match = similar_images[0]
        
        if best_match['similarity'] >= 0.80:  # Alta similitud (reducido de 0.90)
            st.session_state.auto_corrections += 1
            corrected_result = best_match['correct_result']
            
            # Aumentar confianza basada en la similitud
            new_confidence = min(95, current_analysis['validated_confidence'] + 20)  # Boost mayor
            
            st.info(f"üîÑ **Auto-correcci√≥n aplicada**: Imagen muy similar ({best_match['similarity']:.1%}) fue clasificada como **{corrected_result}** en el servidor remoto")
            
            return corrected_result, new_confidence, f"Auto-corregido basado en imagen remota similar: {best_match['filename']}"
        
        elif best_match['similarity'] >= 0.65:  # Similitud media (reducido de 0.80)
            if best_match['correct_result'] != current_analysis['validated_result']:
                st.warning(f"‚ö†Ô∏è **Posible discrepancia**: Imagen similar ({best_match['similarity']:.1%}) en servidor remoto fue clasificada como **{best_match['correct_result']}**")
            
            return current_analysis['validated_result'], current_analysis['validated_confidence'], f"Imagen similar encontrada en remoto: {best_match['filename']} ({best_match['similarity']:.1%})"
        
        else:
            return current_analysis['validated_result'], current_analysis['validated_confidence'], f"Im√°genes similares encontradas en remoto pero con baja similitud ({best_match['similarity']:.1%})"
            
    except Exception as e:
        logger.error(f"Error en auto-correcci√≥n remota: {e}")
        return current_analysis['validated_result'], current_analysis['validated_confidence'], f"Error en auto-correcci√≥n remota: {str(e)}"

def upload_images_to_remote():
    """Sube im√°genes manualmente al servidor remoto para entrenamiento"""
    st.header("üì§ Cargar Im√°genes al Hist√≥rico Remoto")
    
    st.warning("""
    **‚ö†Ô∏è IMPORTANTE:** Sube im√°genes que ya hayas evaluado correctamente.
    El nombre del archivo debe indicar el resultado correcto:
    - `POSITIVE_imagen.jpg`
    - `NEGATIVE_imagen.jpg` 
    - `WEAK_POSITIVE_imagen.jpg`
    - `INVALID_imagen.jpg`
    """)
    
    uploaded_files = st.file_uploader(
        "Selecciona im√°genes para agregar al entrenamiento hist√≥rico",
        type=['jpg', 'jpeg', 'png'],
        accept_multiple_files=True
    )
    
    if uploaded_files and st.button("üöÄ Subir Im√°genes al Servidor Remoto"):
        success_count = 0
        for uploaded_file in uploaded_files:
            try:
                # Leer imagen
                image = Image.open(uploaded_file)
                img_array = np.array(image)
                
                # Determinar resultado del nombre del archivo
                filename = uploaded_file.name.upper()
                if 'POSITIVE' in filename and 'WEAK' not in filename:
                    correct_result = "POSITIVE"
                elif 'NEGATIVE' in filename:
                    correct_result = "NEGATIVE" 
                elif 'WEAK' in filename and 'POSITIVE' in filename:
                    correct_result = "WEAK POSITIVE"
                elif 'INVALID' in filename:
                    correct_result = "INVALID"
                else:
                    st.error(f"‚ùå No se puede determinar resultado para: {uploaded_file.name}")
                    continue
                
                # Guardar en remoto
                analysis_id = f"MANUAL_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{success_count}"
                remote_path = save_remote_training_image(img_array, analysis_id, correct_result)
                
                if remote_path:
                    success_count += 1
                    st.success(f"‚úÖ {uploaded_file.name} ‚Üí {correct_result}")
                
            except Exception as e:
                st.error(f"‚ùå Error procesando {uploaded_file.name}: {e}")
        
        if success_count > 0:
            st.success(f"üéâ {success_count} im√°genes agregadas al hist√≥rico remoto")
            st.info("**Ahora el sistema podr√° hacer auto-correcciones basadas en estas im√°genes**")
        else:
            st.error("‚ùå No se pudo subir ninguna imagen")

def force_learning_from_current_data():
    """Fuerza el aprendizaje con los datos actuales del CSV"""
    st.header("üéØ Entrenamiento Forzado")
    
    if len(st.session_state.learning_data) < 2:
        st.error("Se necesitan al menos 2 ejemplos para entrenar")
        return
    
    st.warning("""
    **ESTA ACCI√ìN:** 
    - Entrenar√° el modelo con TODOS los datos actuales
    - Sobrescribir√° el modelo anterior
    - Forzar√° el aprendizaje incluso con pocos datos
    """)
    
    if st.button("üöÄ EJECUTAR ENTRENAMIENTO FORZADO", type="primary"):
        with st.spinner("Entrenamiento forzado en progreso..."):
            # Usar configuraci√≥n m√°s agresiva para pocos datos
            if len(st.session_state.learning_data) < 10:
                st.session_state.model = RandomForestClassifier(
                    n_estimators=30, 
                    random_state=42, 
                    max_depth=5,  # Menor profundidad para evitar overfitting
                    min_samples_split=2,  # M√°s flexible con pocos datos
                    min_samples_leaf=1
                )
            
            accuracy = train_model()
            
            if accuracy:
                st.success(f"‚úÖ Modelo forzado - Precisi√≥n: {accuracy:.1%}")
                st.info(f"üìä Se usaron {len(st.session_state.learning_data)} ejemplos")
                
                # Mostrar distribuci√≥n de datos
                df = pd.DataFrame(st.session_state.learning_data)
                st.write("**Distribuci√≥n actual:**")
                st.write(df['correct_result'].value_counts())
            else:
                st.error("‚ùå Fall√≥ el entrenamiento forzado")

def clean_corrupted_data():
    """Limpia datos corruptos del dataset remoto"""
    try:
        original_count = len(st.session_state.learning_data)
        cleaned_data = []
        
        for item in st.session_state.learning_data:
            if ('features' in item and 'correct_result' in item and
                isinstance(item['features'], (list, np.ndarray)) and
                len(item['features']) == NUM_FEATURES and
                all(isinstance(x, (int, float, np.number)) for x in item['features'])):
                cleaned_data.append(item)
        
        st.session_state.learning_data = cleaned_data
        save_remote_learning_data()
        st.success(f"üßπ Datos limpiados: {original_count} ‚Üí {len(cleaned_data)} ejemplos v√°lidos")
        
    except Exception as e:
        st.error(f"Error limpiando datos: {e}")

def apply_smart_enhancement(img_array):
    """Aplica mejoras inteligentes a la imagen - MEJORADO"""
    try:
        height, width = img_array.shape[:2]
        
        # Redimensionar si es necesario (especialmente para m√≥viles)
        if height < 400 or width < 400:
            scale_factor = max(600/width, 450/height, 1.5)
            new_width = int(width * scale_factor)
            new_height = int(height * scale_factor)
            img_array = cv2.resize(img_array, (new_width, new_height), interpolation=cv2.INTER_CUBIC)
            st.success(f"üîÑ Imagen mejorada: {width}x{height} ‚Üí {new_width}x{new_height}")
        
        # Mejorar contraste para an√°lisis
        if len(img_array.shape) == 3:
            lab = cv2.cvtColor(img_array, cv2.COLOR_RGB2LAB)
            l, a, b = cv2.split(lab)
            
            # CLAHE para mejorar contraste
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
            l = clahe.apply(l)
            
            lab = cv2.merge([l, a, b])
            img_array = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)
        
        return img_array
    except Exception as e:
        logger.error(f"Error en mejora de imagen: {e}")
        return img_array

def analyze_image_quality_improved(img_array):
    """An√°lisis de calidad MEJORADO - menos estricto"""
    try:
        gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY) if len(img_array.shape) == 3 else img_array
        height, width = gray.shape
        
        brightness = np.mean(gray)
        contrast = np.std(gray)
        sharpness = cv2.Laplacian(gray, cv2.CV_64F).var()
        
        brightness_score = max(0, 100 - abs(brightness - 120) / 255 * 100)
        contrast_score = min(100, contrast / 2.0 * 100)
        sharpness_score = min(100, sharpness / 200 * 100)
        
        quality_score = (brightness_score * 0.3 + contrast_score * 0.4 + sharpness_score * 0.3)
        
        return {
            'brightness': brightness, 
            'contrast': contrast, 
            'sharpness': sharpness,
            'resolution': f"{width}x{height}", 
            'quality_score': quality_score,
            'quality_category': 'BUENA' if quality_score > 50 else 'ACEPTABLE' if quality_score > 30 else 'BAJA'
        }
    except:
        return {'quality_score': 60, 'quality_category': 'ACEPTABLE'}

def detect_chagas_bands_improved(img_array):
    """Detecci√≥n de bandas MEJORADA - menos estricta"""
    try:
        gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY) if len(img_array.shape) == 3 else img_array
        height, width = gray.shape
        
        control_region = gray[int(height*0.25):int(height*0.75), int(width*0.55):int(width*0.80)]
        test_region = gray[int(height*0.25):int(height*0.75), int(width*0.20):int(width*0.45)]
        background_region = gray[int(height*0.1):int(height*0.2), int(width*0.1):int(width*0.2)]
        
        control_mean = np.mean(control_region) if control_region.size > 0 else 255
        test_mean = np.mean(test_region) if test_region.size > 0 else 255
        background_mean = np.mean(background_region) if background_region.size > 0 else 255
        
        control_present = (background_mean - control_mean) > 15
        test_present = (background_mean - test_mean) > 10
        
        control_diff = background_mean - control_mean
        test_diff = background_mean - test_mean
        
        base_confidence = 60
        
        if not control_present:
            result = "INVALID"
            confidence = max(30, base_confidence - 30)
        elif control_present and not test_present:
            result = "NEGATIVE"
            confidence = min(90, base_confidence + 20 + min(control_diff/2, 20))
        elif control_present and test_present:
            intensity_ratio = test_mean / control_mean if control_mean > 0 else 1
            if intensity_ratio < 0.8:
                result = "POSITIVE"
                confidence = min(85, base_confidence + 15 + min(test_diff/2, 15))
            else:
                result = "WEAK POSITIVE"
                confidence = min(75, base_confidence + 10 + min(test_diff/2, 10))
        else:
            result = "INDETERMINADO"
            confidence = 50
            
        return {
            'result': result, 
            'confidence': confidence,
            'control_present': control_present, 
            'test_present': test_present,
            'control_intensity': control_mean, 
            'test_intensity': test_mean,
            'intensity_ratio': test_mean/control_mean if control_mean > 0 else 0
        }
    except Exception as e:
        logger.error(f"Error en detecci√≥n de bandas: {e}")
        return {'result': 'INDETERMINADO', 'confidence': 40, 'control_present': False, 'test_present': False}

def detect_text_on_strip(img_array):
    """Detecci√≥n general de texto"""
    try:
        gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY) if len(img_array.shape) == 3 else img_array
        custom_config = r'--oem 3 --psm 6'
        detected_text = pytesseract.image_to_string(gray, config=custom_config)
        cleaned = ' '.join(detected_text.split())
        keywords = ['CHAGAS', 'TEST', 'CONTROL', 'POSITIVE', 'NEGATIVE', 'INVALID', 'C', 'T']
        found_keywords = [k for k in keywords if k in cleaned.upper()]
        return {
            'raw_text': cleaned, 
            'keywords': found_keywords,
            'has_chagas_text': 'CHAGAS' in found_keywords,
            'has_control_text': 'CONTROL' in found_keywords or 'C' in found_keywords,
            'has_test_text': 'TEST' in found_keywords or 'T' in found_keywords
        }
    except:
        return {"raw_text": "", "keywords": [], "has_chagas_text": False}

def detect_letters_c_t_improved(img_array):
    """Detecci√≥n MEJORADA de letras C y T con m√∫ltiples m√©todos"""
    try:
        gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY) if len(img_array.shape) == 3 else img_array
        height, width = gray.shape
        
        results = {
            'C_detected': False,
            'T_detected': False,
            'C_confidence': 0,
            'T_confidence': 0,
            'letters_found': []
        }
        
        ocr_results = detect_letters_ocr_optimized(gray, height, width)
        contour_results = detect_letters_contours(gray, height, width)
        
        if ocr_results['C_detected'] or contour_results['C_detected']:
            results['C_detected'] = True
            results['C_confidence'] = max(ocr_results['C_confidence'], contour_results['C_confidence'])
            
        if ocr_results['T_detected'] or contour_results['T_detected']:
            results['T_detected'] = True
            results['T_confidence'] = max(ocr_results['T_confidence'], contour_results['T_confidence'])
        
        if results['C_detected']:
            results['letters_found'].append('C')
        if results['T_detected']:
            results['letters_found'].append('T')
            
        return results
        
    except Exception as e:
        logger.error(f"Error en detecci√≥n de letras: {e}")
        return {
            'C_detected': False, 'T_detected': False,
            'C_confidence': 0, 'T_confidence': 0,
            'letters_found': []
        }

def detect_letters_ocr_optimized(gray, height, width):
    """OCR optimizado para letras C y T"""
    try:
        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
        enhanced = clahe.apply(gray)
        
        binary = cv2.adaptiveThreshold(enhanced, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                      cv2.THRESH_BINARY, 11, 2)
        
        kernel = np.ones((2,2), np.uint8)
        binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
        binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)
        
        custom_config = r'--oem 3 --psm 8 -c tessedit_char_whitelist=CTct'
        
        regions_to_check = [
            (int(width*0.15), int(height*0.4), int(width*0.30), int(height*0.6)),
            (int(width*0.65), int(height*0.4), int(width*0.80), int(height*0.6)),
            (int(width*0.10), int(height*0.3), int(width*0.25), int(height*0.5)),
            (int(width*0.70), int(height*0.3), int(width*0.85), int(height*0.5))
        ]
        
        C_detected = False
        T_detected = False
        C_confidence = 0
        T_confidence = 0
        
        for i, (x1, y1, x2, y2) in enumerate(regions_to_check):
            region = binary[y1:y2, x1:x2]
            if region.size == 0:
                continue
                
            detected_text = pytesseract.image_to_string(region, config=custom_config)
            cleaned_text = re.sub(r'[^CTct]', '', detected_text.upper())
            
            region_confidence = calculate_text_confidence(region)
            
            if 'C' in cleaned_text and region_confidence > C_confidence:
                C_detected = True
                C_confidence = region_confidence
                
            if 'T' in cleaned_text and region_confidence > T_confidence:
                T_detected = True
                T_confidence = region_confidence
        
        return {
            'C_detected': C_detected,
            'T_detected': T_detected,
            'C_confidence': C_confidence,
            'T_confidence': T_confidence
        }
        
    except Exception as e:
        logger.warning(f"OCR para letras fall√≥: {e}")
        return {'C_detected': False, 'T_detected': False, 'C_confidence': 0, 'T_confidence': 0}

def detect_letters_contours(gray, height, width):
    """Detecci√≥n de letras usando procesamiento de contornos"""
    try:
        blurred = cv2.GaussianBlur(gray, (3, 3), 0)
        edges = cv2.Canny(blurred, 50, 150)
        
        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        C_candidates = []
        T_candidates = []
        
        for contour in contours:
            area = cv2.contourArea(contour)
            if area < 30 or area > 2000:
                continue
                
            x, y, w, h = cv2.boundingRect(contour)
            aspect_ratio = w / h
            
            if 0.3 < aspect_ratio < 3.0:
                if x > width * 0.6:
                    C_candidates.append((x, y, w, h, area))
                elif x < width * 0.4:
                    T_candidates.append((x, y, w, h, area))
        
        C_detected = len(C_candidates) > 0
        T_detected = len(T_candidates) > 0
        
        C_confidence = min(80, len(C_candidates) * 20) if C_detected else 0
        T_confidence = min(80, len(T_candidates) * 20) if T_detected else 0
        
        return {
            'C_detected': C_detected,
            'T_detected': T_detected,
            'C_confidence': C_confidence,
            'T_confidence': T_confidence
        }
        
    except Exception as e:
        logger.error(f"Error en detecci√≥n por contornos: {e}")
        return {'C_detected': False, 'T_detected': False, 'C_confidence': 0, 'T_confidence': 0}

def calculate_text_confidence(region):
    """Calcula confianza basada en la claridad del texto"""
    try:
        edges = cv2.Canny(region, 50, 150)
        edge_density = np.sum(edges > 0) / edges.size
        
        contrast = np.std(region)
        
        confidence = (edge_density * 50 + min(contrast/5, 30))
        return min(90, confidence)
        
    except:
        return 50

def validate_with_letters(chagas_analysis, quality_analysis, text_detection, letters_detection):
    """Validaci√≥n MEJORADA - mucho menos estricta"""
    confidence = chagas_analysis['confidence']
    quality_score = quality_analysis['quality_score']
    
    quality_factor = 0.5 + (quality_score / 100.0) * 0.5
    adjusted_confidence = confidence * quality_factor
    
    if letters_detection:
        if letters_detection['C_detected']:
            adjusted_confidence += 10
        if letters_detection['T_detected']:
            adjusted_confidence += 10
    
    final_confidence = min(95, adjusted_confidence)
    
    if quality_score < 20:
        result = "INDETERMINADO"
        notes = "Calidad de imagen muy baja"
    elif final_confidence < 40:
        result = "INDETERMINADO" 
        notes = "Confianza insuficiente"
    else:
        result = chagas_analysis['result']
        notes = "An√°lisis completado"
        
        if letters_detection and letters_detection['letters_found']:
            notes += f" - Letras: {', '.join(letters_detection['letters_found'])}"
    
    return {
        'validated_result': result,
        'validated_confidence': final_confidence,
        'validation_notes': notes,
        'quality_score': quality_score
    }

def render_capture_tab():
    """Pesta√±a de captura y an√°lisis principal - COMPLETAMENTE MEJORADA"""
    st.header("ü™≥ An√°lisis Principal con ML Remoto")
    
    if len(st.session_state.learning_data) >= 2 and st.session_state.training_count > 0:
        st.success("‚úÖ Sistema de ML remoto activo - Usando aprendizaje acumulado en servidor")
    else:
        st.info("üîÑ Sistema en fase de aprendizaje - Necesita m√°s evaluaciones")
    
    # Secci√≥n de c√°mara MEJORADA
    st.subheader("üì∑ Captura con C√°mara")
    
    # Informaci√≥n expandible sobre problemas de c√°mara
    with st.expander("üîß ¬øProblemas con la c√°mara? Haz clic aqu√≠ para soluci√≥n completa"):
        check_camera_access()
    
    # Usar la funci√≥n MEJORADA de captura de c√°mara
    picture = enhance_camera_capture()
    
    if picture is not None:
        process_image_for_analysis(picture, "C√°mara")
    
    # Alternativa de subida de archivo
    st.subheader("üìÅ Subir Archivo (Alternativa)")
    uploaded_file = st.file_uploader(
        "O sube una imagen desde tu dispositivo", 
        type=['jpg', 'jpeg', 'png'],
        help="Formatos aceptados: JPG, JPEG, PNG"
    )
    
    if uploaded_file is not None:
        process_image_for_analysis(uploaded_file, "Archivo")
        st.success("‚úÖ Archivo cargado correctamente")

def process_image_for_analysis(picture, source):
    """Procesa imagen para an√°lisis con ML remoto"""
    try:
        image = Image.open(picture)
        img_array = np.array(image)
        
        with st.spinner("üîç Analizando imagen y consultando servidor remoto..."):
            enhanced_img = apply_smart_enhancement(img_array)
            quality_analysis = analyze_image_quality_improved(enhanced_img)
            chagas_analysis = detect_chagas_bands_improved(enhanced_img)
            text_detection = detect_text_on_strip(enhanced_img)
            
            letters_detection = None
            if st.session_state.detect_letters:
                letters_detection = detect_letters_c_t_improved(enhanced_img)
            
            validated_analysis = validate_with_letters(
                chagas_analysis, quality_analysis, text_detection, letters_detection
            )
            
            features = extract_features_from_analysis({
                **chagas_analysis,
                'quality_analysis': quality_analysis,
                'text_detection': text_detection,
                'letters_detection': letters_detection,
                'validated_confidence': validated_analysis['validated_confidence'],
                'quality_score': validated_analysis['quality_score']
            })
            
            ml_prediction, ml_confidence = predict_with_model(features)
            
            final_result = validated_analysis['validated_result']
            final_confidence = validated_analysis['validated_confidence']
            correction_notes = "Sin auto-correcci√≥n aplicada"
            
            if st.session_state.auto_correction and len(st.session_state.learning_data) > 0:
                corrected_result, corrected_confidence, notes = auto_correct_with_historical_data(
                    validated_analysis, enhanced_img
                )
                final_result = corrected_result
                final_confidence = corrected_confidence
                correction_notes = notes
            
            if ml_prediction and ml_confidence > 0.5:  # Umbral m√°s bajo
                final_result = ml_prediction
                final_confidence = ml_confidence * 100
            
            final_analysis = {
                **validated_analysis,
                'validated_result': final_result,
                'validated_confidence': final_confidence,
                'features': features,
                'ml_prediction': ml_prediction,
                'ml_confidence': ml_confidence,
                'analysis_id': datetime.now().strftime('%Y%m%d_%H%M%S'),
                'image_array': enhanced_img,
                'letters_detection': letters_detection,
                'text_detection': text_detection,
                'correction_notes': correction_notes,
                'source': source
            }
        
        display_analysis_results(final_analysis, enhanced_img)
        
        st.session_state.last_analysis = final_analysis
        st.session_state.last_image = enhanced_img
        
    except Exception as e:
        st.error(f"‚ùå Error en an√°lisis: {e}")

def display_analysis_results(analysis, image):
    """Muestra resultados del an√°lisis"""
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üñºÔ∏è Imagen Analizada")
        st.image(image, use_container_width=True)
        
        if analysis.get('correction_notes') and "auto-correcci√≥n" in analysis['correction_notes'].lower():
            st.info(f"**üîÑ Auto-correcci√≥n:** {analysis['correction_notes']}")
    
    with col2:
        st.subheader("üéØ Resultados")
        
        if analysis['ml_prediction'] and analysis['ml_confidence'] > 0:
            st.info(f"ü§ñ ML: {analysis['ml_prediction']} ({analysis['ml_confidence']:.1%})")
        
        result_config = {
            "POSITIVE": {"icon": "üî¥", "color": "#dc3545", "bg_color": "#f8d7da"},
            "NEGATIVE": {"icon": "üü¢", "color": "#28a745", "bg_color": "#d4edda"},
            "WEAK POSITIVE": {"icon": "üü°", "color": "#ffc107", "bg_color": "#fff3cd"},
            "INVALID": {"icon": "üîµ", "color": "#17a2b8", "bg_color": "#d1ecf1"},
            "INDETERMINADO": {"icon": "‚ö´", "color": "#6c757d", "bg_color": "#f8f9fa"}
        }
        
        config = result_config.get(analysis['validated_result'], result_config["INDETERMINADO"])
        
        st.markdown(f"""
        <div style='background-color: {config["bg_color"]}; padding: 20px; border-radius: 10px; border-left: 5px solid {config["color"]};'>
            <h2 style='color: {config["color"]}; margin: 0;'>{config["icon"]} {analysis['validated_result']}</h2>
            <p style='margin: 10px 0; font-size: 1.2em;'><strong>Confianza:</strong> {analysis['validated_confidence']:.1f}%</p>
            <p style='margin: 0;'><strong>Calidad:</strong> {analysis['quality_score']:.1f}/100</p>
        </div>
        """, unsafe_allow_html=True)
        
        if analysis.get('letters_detection'):
            display_letters_info(analysis['letters_detection'])
        
        if analysis.get('text_detection') and analysis['text_detection'].get('keywords'):
            st.write("**üî§ Texto detectado:**")
            st.write(f"Palabras clave: {', '.join(analysis['text_detection']['keywords'])}")
    
    st.markdown("---")
    st.subheader("üìù Evaluaci√≥n R√°pida")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("‚úÖ Correcto", use_container_width=True, type="primary"):
            save_evaluation("correct", analysis, image, analysis['validated_result'])
    
    with col2:
        if st.button("‚ùå Incorrecto", use_container_width=True):
            st.session_state.show_correction = True
            st.rerun()
    
    if st.session_state.get('show_correction', False):
        st.markdown("---")
        st.subheader("‚úèÔ∏è Correcci√≥n del Resultado")
        
        correct_result = st.selectbox(
            "Selecciona el resultado correcto:",
            RESULT_CATEGORIES,
            index=RESULT_CATEGORIES.index(analysis['validated_result']) if analysis['validated_result'] in RESULT_CATEGORIES else 0
        )
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("üíæ Guardar Correcci√≥n", use_container_width=True, type="primary"):
                save_evaluation("incorrect", analysis, image, correct_result)
                st.session_state.show_correction = False
                st.rerun()
        
        with col2:
            if st.button("‚Ü©Ô∏è Cancelar", use_container_width=True):
                st.session_state.show_correction = False
                st.rerun()

def display_letters_info(letters_detection):
    """Muestra informaci√≥n de letras detectadas"""
    st.write("**üî§ Letras detectadas:**")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if letters_detection['C_detected']:
            st.success(f"‚úÖ **Letra C detectada** (Confianza: {letters_detection['C_confidence']:.0f}%)")
        else:
            st.error("‚ùå **Letra C no detectada**")
    
    with col2:
        if letters_detection['T_detected']:
            st.success(f"‚úÖ **Letra T detectada** (Confianza: {letters_detection['T_confidence']:.0f}%)")
        else:
            st.error("‚ùå **Letra T no detectada**")
    
    if letters_detection['letters_found']:
        st.info(f"üìù **Letras identificadas:** {', '.join(letters_detection['letters_found'])}")

def save_evaluation(evaluation_type, analysis, image, correct_result):
    """Guarda evaluaci√≥n del usuario en servidor remoto - VERSI√ìN MEJORADA"""
    try:
        learning_item = {
            'timestamp': datetime.now().isoformat(),
            'features': analysis['features'],
            'predicted_result': analysis['validated_result'],
            'correct_result': correct_result,
            'confidence': analysis['validated_confidence'],
            'quality_score': analysis['quality_score'],
            'evaluation_type': evaluation_type,
            'source': analysis.get('source', 'desconocido'),
            'analysis_id': analysis['analysis_id']
        }
        
        st.session_state.learning_data.append(learning_item)
        save_remote_learning_data()
        
        # ‚úÖ FORZAR guardado de imagen incluso si hay errores
        max_retries = 3
        image_saved = False
        for attempt in range(max_retries):
            try:
                image_path = save_remote_training_image(image, analysis['analysis_id'], correct_result)
                if image_path:
                    image_saved = True
                    break
                else:
                    logger.warning(f"Reintentando guardar imagen... ({attempt + 1}/{max_retries})")
                    time.sleep(1)
            except Exception as e:
                logger.warning(f"Error guardando imagen, reintentando... ({attempt + 1}/{max_retries}): {e}")
                time.sleep(1)
        
        if not image_saved:
            st.warning("‚ö†Ô∏è No se pudo guardar la imagen, pero los datos se guardaron correctamente")
        
        if evaluation_type == "correct":
            st.success("‚úÖ Evaluaci√≥n guardada en servidor remoto - El sistema aprender√° de este acierto")
        else:
            st.success("‚úÖ Correcci√≥n guardada en servidor remoto - El sistema se ajustar√° para mejorar")
            
        # ‚úÖ Entrenar inmediatamente despu√©s de guardar (m√°s agresivo)
        if len(st.session_state.learning_data) >= 2:  # Baj√≥ el m√≠nimo a 2
            with st.spinner("üîÑ Entrenando modelo inmediatamente..."):
                accuracy = train_model()
                if accuracy:
                    st.success(f"üéØ Modelo actualizado - Precisi√≥n: {accuracy:.1%}")
        
    except Exception as e:
        st.error(f"Error guardando evaluaci√≥n en remoto: {e}")

def render_evaluation_tab():
    """Pesta√±a de evaluaci√≥n detallada"""
    st.header("üìä Evaluaci√≥n y Correcci√≥n")
    
    if 'last_analysis' not in st.session_state:
        st.info("Realiza un an√°lisis primero en la pesta√±a 'An√°lisis'")
        return
    
    analysis = st.session_state.last_analysis
    image = st.session_state.last_image
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üñºÔ∏è Imagen a Evaluar")
        st.image(image, use_container_width=True)
        
        st.write("**Resultado del sistema:**")
        st.write(f"- **Predicci√≥n:** {analysis['validated_result']}")
        st.write(f"- **Confianza:** {analysis['validated_confidence']:.1f}%")
        st.write(f"- **Calidad:** {analysis['quality_score']:.1f}/100")
        
        if analysis['ml_prediction']:
            st.write(f"- **ML:** {analysis['ml_prediction']} ({analysis['ml_confidence']:.1%})")
        
        if analysis.get('correction_notes'):
            st.write(f"- **Notas:** {analysis['correction_notes']}")
    
    with col2:
        st.subheader("‚úèÔ∏è Evaluaci√≥n Detallada")
        
        st.write("**Evaluaci√≥n del resultado:**")
        
        col_correct, col_incorrect = st.columns(2)
        
        with col_correct:
            if st.button("‚úÖ CORRECTO", use_container_width=True, type="primary"):
                save_evaluation("correct", analysis, image, analysis['validated_result'])
                st.rerun()
        
        with col_incorrect:
            if st.button("‚ùå INCORRECTO", use_container_width=True):
                save_evaluation("incorrect", analysis, image, analysis['validated_result'])
                st.rerun()
        
        st.markdown("---")
        st.subheader("üìù Correcci√≥n Manual")
        
        st.write("**Selecciona el resultado correcto:**")
        
        cols = st.columns(2)
        
        with cols[0]:
            if st.button("üî¥ POSITIVE", use_container_width=True):
                save_training_example(analysis, image, "POSITIVE")
                st.rerun()
            
            if st.button("üü¢ NEGATIVE", use_container_width=True):
                save_training_example(analysis, image, "NEGATIVE")
                st.rerun()
        
        with cols[1]:
            if st.button("üü° WEAK POSITIVE", use_container_width=True):
                save_training_example(analysis, image, "WEAK POSITIVE")
                st.rerun()
            
            if st.button("üîµ INVALID", use_container_width=True):
                save_training_example(analysis, image, "INVALID")
                st.rerun()

def save_training_example(analysis, image, correct_result):
    """Guarda ejemplo para entrenamiento en servidor remoto"""
    try:
        learning_item = {
            'timestamp': datetime.now().isoformat(),
            'features': analysis['features'],
            'predicted_result': analysis['validated_result'],
            'correct_result': correct_result,
            'confidence': analysis['validated_confidence'],
            'quality_score': analysis['quality_score'],
            'evaluation_type': 'manual',
            'source': analysis.get('source', 'manual'),
            'analysis_id': analysis['analysis_id']
        }
        
        st.session_state.learning_data.append(learning_item)
        save_remote_learning_data()
        
        # Guardar imagen con m√∫ltiples intentos
        max_retries = 3
        for attempt in range(max_retries):
            try:
                save_remote_training_image(image, analysis['analysis_id'], correct_result)
                break
            except Exception as e:
                if attempt == max_retries - 1:
                    st.warning("No se pudo guardar la imagen despu√©s de varios intentos")
        
        st.success(f"‚úÖ Ejemplo {correct_result} guardado para entrenamiento en servidor remoto")
        
        # Entrenar inmediatamente
        if len(st.session_state.learning_data) >= 2:
            with st.spinner("üîÑ Re-entrenando modelo en servidor remoto..."):
                accuracy = train_model()
                if accuracy:
                    st.success(f"üéØ Modelo actualizado en servidor remoto - Precisi√≥n: {accuracy:.1%}")
        
    except Exception as e:
        st.error(f"Error guardando ejemplo en remoto: {e}")

def create_improved_accuracy_chart():
    """Crea un gr√°fico mejorado de la evoluci√≥n de la precisi√≥n"""
    if not st.session_state.accuracy_history:
        st.info("No hay datos de precisi√≥n para mostrar")
        return
    
    try:
        # Crear figura con mejor estilo
        fig, ax = plt.subplots(figsize=(12, 6))
        
        # Preparar datos
        history_df = pd.DataFrame(st.session_state.accuracy_history)
        history_df['timestamp'] = pd.to_datetime(history_df['timestamp'])
        history_df = history_df.sort_values('timestamp')
        
        # Crear gr√°fico con mejor estilo
        ax.plot(history_df['timestamp'], history_df['accuracy'], 
                marker='o', linewidth=2.5, markersize=8, 
                color='#2E86AB', markerfacecolor='#A23B72', 
                markeredgecolor='white', markeredgewidth=1.5,
                label='Precisi√≥n del Modelo')
        
        # Configurar l√≠mites para mejor visualizaci√≥n
        min_accuracy = max(0.0, history_df['accuracy'].min() - 0.1)
        max_accuracy = min(1.0, history_df['accuracy'].max() + 0.1)
        ax.set_ylim(min_accuracy, max_accuracy)
        
        # Configurar eje X para mostrar tiempos claramente
        ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))
        ax.xaxis.set_major_locator(mdates.AutoDateLocator())
        plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')
        
        # Configurar eje Y para mostrar porcentajes
        ax.yaxis.set_major_formatter(ticker.PercentFormatter(1.0))
        ax.yaxis.set_major_locator(ticker.MultipleLocator(0.1))
        
        # A√±adir cuadr√≠cula para mejor lectura
        ax.grid(True, alpha=0.3)
        ax.grid(True, which='minor', alpha=0.2)
        
        # A√±adir t√≠tulo y etiquetas
        ax.set_title('Evoluci√≥n de la Precisi√≥n del Modelo', 
                    fontsize=14, fontweight='bold', pad=20)
        ax.set_xlabel('Tiempo', fontsize=12, labelpad=10)
        ax.set_ylabel('Precisi√≥n', fontsize=12, labelpad=10)
        
        # A√±adir leyenda
        ax.legend(loc='lower right', fontsize=10, framealpha=0.9)
        
        # A√±adir √°rea sombreada para resaltar la mejora
        ax.fill_between(history_df['timestamp'], history_df['accuracy'], 
                       alpha=0.2, color='#2E86AB')
        
        # A√±adir anotaciones para puntos importantes
        if len(history_df) > 1:
            # Punto de mayor precisi√≥n
            max_idx = history_df['accuracy'].idxmax()
            max_point = history_df.loc[max_idx]
            ax.annotate(f'M√°ximo: {max_point["accuracy"]:.1%}', 
                       xy=(max_point['timestamp'], max_point['accuracy']),
                       xytext=(10, 30), textcoords='offset points',
                       arrowprops=dict(arrowstyle='->', color='#A23B72'),
                       fontsize=9, color='#A23B72')
        
        # Ajustar el dise√±o
        plt.tight_layout()
        
        # Mostrar el gr√°fico en Streamlit
        st.pyplot(fig)
        
        # Mostrar estad√≠sticas
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Precisi√≥n Actual", 
                     f"{history_df['accuracy'].iloc[-1]:.1%}")
        with col2:
            st.metric("Mejor Precisi√≥n", 
                     f"{history_df['accuracy'].max():.1%}")
        with col3:
            st.metric("Mejora Total", 
                     f"{(history_df['accuracy'].iloc[-1] - history_df['accuracy'].iloc[0]):.1%}")
            
    except Exception as e:
        st.error(f"Error generando gr√°fico: {e}")
        # Fallback: gr√°fico simple
        if st.session_state.accuracy_history:
            history_df = pd.DataFrame(st.session_state.accuracy_history)
            st.line_chart(history_df.set_index('timestamp')['accuracy'])

def render_learning_tab():
    """Pesta√±a de gesti√≥n del aprendizaje remoto - VERSI√ìN MEJORADA"""
    st.header("üß† Gesti√≥n del Aprendizaje Autom√°tico Remoto")
    
    # NUEVO: Secci√≥n de herramientas avanzadas
    st.subheader("üõ†Ô∏è Herramientas Avanzadas de Entrenamiento")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("üöÄ Entrenamiento Forzado", use_container_width=True, type="primary"):
            force_learning_from_current_data()
            
    with col2:
        if st.button("üì§ Cargar Im√°genes Hist√≥ricas", use_container_width=True):
            upload_images_to_remote()
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üìä Estado del Modelo Remoto")
        
        st.metric("Ejemplos de Entrenamiento", len(st.session_state.learning_data))
        st.metric("Sesiones de Entrenamiento", st.session_state.training_count)
        st.metric("Auto-correcciones", st.session_state.auto_corrections)
        
        if st.session_state.accuracy_history:
            latest = st.session_state.accuracy_history[-1]
            st.metric("Precisi√≥n Actual", f"{latest['accuracy']:.1%}")
        
        remote_images = load_remote_images_list()
        st.metric("Im√°genes en Servidor", len(remote_images))
        
        if st.session_state.learning_data:
            df = pd.DataFrame(st.session_state.learning_data)
            result_counts = df['correct_result'].value_counts()
            st.write("**Distribuci√≥n de resultados:**")
            for result in RESULT_CATEGORIES:
                count = result_counts.get(result, 0)
                st.write(f"- {result}: {count}")
    
    with col2:
        st.subheader("üõ†Ô∏è Acciones de Entrenamiento Remoto")
        
        if st.button("üéØ Entrenar Modelo Ahora", use_container_width=True):
            with st.spinner("Entrenando modelo en servidor remoto..."):
                accuracy = train_model()
                if accuracy:
                    st.success(f"‚úÖ Modelo entrenado en servidor remoto - Precisi√≥n: {accuracy:.1%}")
                else:
                    st.error("‚ùå No hay suficientes datos para entrenar")
        
        if st.button("üìä Ver Todos los Datos", use_container_width=True):
            display_learning_data()
        
        if st.button("üîÑ Sincronizar con Remoto", use_container_width=True):
            st.session_state.learning_data = load_remote_learning_data()
            st.session_state.accuracy_history = load_remote_accuracy_history()
            st.success("‚úÖ Datos sincronizados con servidor remoto")
            st.rerun()
        
        if st.button("üìã Listar Im√°genes Remotas", use_container_width=True):
            remote_images = load_remote_images_list()
            if remote_images:
                st.write(f"**Im√°genes en servidor remoto ({len(remote_images)}):**")
                for img in remote_images[:10]:  # Mostrar primeras 10
                    st.write(f"- {img}")
                if len(remote_images) > 10:
                    st.write(f"... y {len(remote_images) - 10} m√°s")
            else:
                st.info("No hay im√°genes en el servidor remoto")
                
        if st.button("üìù Crear Encabezados Remotos", use_container_width=True):
            if create_remote_headers():
                st.rerun()
    
    # NUEVO: Gr√°fico mejorado de evoluci√≥n de precisi√≥n
    if st.session_state.accuracy_history:
        st.subheader("üìà Evoluci√≥n de la Precisi√≥n - Gr√°fico Mejorado")
        create_improved_accuracy_chart()

def display_learning_data():
    """Muestra los datos de aprendizaje remotos"""
    if not st.session_state.learning_data:
        st.info("No hay datos de aprendizaje en el servidor remoto")
        return
    
    df = pd.DataFrame(st.session_state.learning_data)
    
    st.subheader("üìã Datos de Aprendizaje Remotos")
    st.dataframe(df)
    
    st.subheader("üìä Estad√≠sticas de Datos Remotos")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Total Ejemplos", len(df))
        correct_count = len(df[df['evaluation_type'] == 'correct'])
        st.metric("Evaluaciones Correctas", correct_count)
    
    with col2:
        st.write("**Distribuci√≥n de Resultados Correctos:**")
        result_counts = df['correct_result'].value_counts()
        for result in RESULT_CATEGORIES:
            count = result_counts.get(result, 0)
            st.write(f"- {result}: {count}")
    
    with col3:
        st.write("**Tipos de Evaluaci√≥n:**")
        eval_counts = df['evaluation_type'].value_counts()
        st.write(eval_counts)

def render_guide_tab():
    """Pesta√±a de gu√≠a del sistema de aprendizaje remoto"""
    st.header("üìö Gu√≠a del Sistema de Aprendizaje Remoto")
    
    st.markdown("""
    ### ü™≥ SISTEMA 100% REMOTO - TODOS LOS ARCHIVOS EN SERVIDOR
    
    **üìÅ ARCHIVOS GUARDADOS EN SERVIDOR:**
    
    - `registro_chagas.csv` - Datos de aprendizaje (caracter√≠sticas + resultados)
    - `chagas_model.pkl` - Modelo de Machine Learning entrenado
    - `accuracy_history.json` - Historial de precisi√≥n del modelo
    - `training_images/` - Directorio con todas las im√°genes de entrenamiento
    
    **üîÑ FLUJO DE APRENDIZAJE REMOTO:**
    
    1. **üì∏ Captura**: Toma foto con c√°mara o sube archivo
    2. **üîç An√°lisis**: Sistema analiza imagen localmente
    3. **üåê Consulta remota**: Busca im√°genes similares en servidor
    4. **ü§ñ ML + Auto-correcci√≥n**: Combina ML local con hist√≥rico remoto
    5. **‚úÖ Evaluaci√≥n**: Usuario confirma o corrige resultado
    6. **üíæ Guardado remoto**: Todo se guarda en servidor inmediatamente
    
    **üéØ BENEFICIOS DEL SISTEMA REMOTO:**
    
    - **Persistencia total**: No se pierden datos al reiniciar
    - **Colaborativo**: M√∫ltiples usuarios contribuyen al aprendizaje
    - **Escalable**: El servidor maneja todo el almacenamiento
    - **Seguro**: Datos centralizados y respaldados
    - **Consistente**: Todos usan el mismo modelo actualizado
    
    **üîß ARCHIVOS EN SERVIDOR REMOTO:**
    """)
    
    # Mostrar estructura de archivos remotos
    st.code("""
    /home/POLANCO6/CHAGAS/
    ‚îú‚îÄ‚îÄ registro_chagas.csv          # Datos de aprendizaje
    ‚îú‚îÄ‚îÄ chagas_model.pkl             # Modelo ML entrenado  
    ‚îú‚îÄ‚îÄ accuracy_history.json        # Historial de precisi√≥n
    ‚îî‚îÄ‚îÄ training_images/             # Im√°genes de entrenamiento
        ‚îú‚îÄ‚îÄ 20240115103000_POSITIVE_20240115103015.jpg
        ‚îú‚îÄ‚îÄ 20240115103245_NEGATIVE_20240115103250.jpg
        ‚îú‚îÄ‚îÄ 20240115103520_WEAK_POSITIVE_20240115103525.jpg
        ‚îî‚îÄ‚îÄ ...
    """, language="bash")
    
    st.success("""
    **üöÄ CONSEJO R√ÅPIDO:** 
    El sistema funciona completamente desde el servidor remoto. 
    No se guarda nada localmente - todo est√° centralizado para m√°ximo aprendizaje colaborativo.
    """)

# Pesta√±as principales
def main():
    st.set_page_config(
        page_title="Analizador Chagas con Aprendizaje Autom√°tico Remoto",
        page_icon="ü™≥",  # CAMBIADO: Chinche besucona en lugar de mosquito
        layout="centered",
        initial_sidebar_state="expanded"
    )
    
    initialize_learning_system()
    check_https_status()
    
    st.title("ü™≥ Analizador Chagas con APRENDIZAJE AUTOM√ÅTICO REMOTO")  # CAMBIADO: Icono de chinche
    st.markdown("### **Sistema que mejora con cada evaluaci√≥n - Almacenamiento 100% Remoto**")
    
    with st.sidebar:
        st.header("üß† Sistema de Aprendizaje Remoto")
        
        st.metric("Ejemplos de Entrenamiento", len(st.session_state.learning_data))
        st.metric("Sesiones de Entrenamiento", st.session_state.training_count)
        st.metric("Auto-correcciones", st.session_state.auto_corrections)
        
        if st.session_state.accuracy_history:
            latest_accuracy = st.session_state.accuracy_history[-1]['accuracy']
            st.metric("Precisi√≥n Actual", f"{latest_accuracy:.1%}")
        
        progress = min(len(st.session_state.learning_data) / 20, 1.0)
        st.progress(progress)
        st.caption(f"Progreso: {len(st.session_state.learning_data)}/20 ejemplos")
        
        st.markdown("---")
        st.header("‚öôÔ∏è Configuraci√≥n")
        st.session_state.detect_letters = st.checkbox("Detecci√≥n de Letras C/T", value=True)
        st.session_state.auto_correction = st.checkbox("Auto-correcci√≥n con hist√≥rico remoto", value=True)
        st.session_state.min_confidence = st.slider("Confianza M√≠nima (%)", 50, 90, 60)
        
        if st.button("üîÑ Re-entrenar Modelo", use_container_width=True):
            accuracy = train_model()
            if accuracy:
                st.success(f"‚úÖ Modelo re-entrenado - Precisi√≥n: {accuracy:.1%}")
            else:
                st.error("‚ùå No hay suficientes datos para entrenar")
        
        if st.button("üßπ Limpiar Datos Corruptos", use_container_width=True):
            clean_corrupted_data()
            st.rerun()

        st.markdown("---")
        st.header("üåê Almacenamiento Remoto")
        st.info(f"**Servidor:** {REMOTE_HOST}:{REMOTE_PORT}")
        st.info(f"**Usuario:** {REMOTE_USER}")
        st.info(f"**Directorio:** {REMOTE_DIR}")
        
        remote_images = load_remote_images_list()
        st.info(f"**Im√°genes en remoto:** {len(remote_images)}")
        
        if st.button("üîÑ Sincronizar con Remoto", use_container_width=True):
            st.session_state.learning_data = load_remote_learning_data()
            st.session_state.accuracy_history = load_remote_accuracy_history()
            st.success("‚úÖ Datos sincronizados con servidor remoto")
            st.rerun()
    
    tab1, tab2, tab3, tab4 = st.tabs([
        "ü™≥ An√°lisis", "üìä Evaluaci√≥n", "üß† Aprendizaje", "üìö Gu√≠a"  # CAMBIADO: Icono de chinche
    ])
    
    with tab1:
        render_capture_tab()
    with tab2:
        render_evaluation_tab()
    with tab3:
        render_learning_tab()
    with tab4:
        render_guide_tab()

if __name__ == "__main__":
    main()
